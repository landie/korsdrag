%TODO: \begin{figure} på alla bilder.. måste även bestämma om caption ska över eller under figure/table.


\section{Testing framework}
This testing framework aims to answer RQ3. The goal is to produce a transparent and sound way of testing core functionality \cite{lit review} performance of any ESB. 
We have gathered much inspiration from Sanjay \cite{Sanjay} regarding what measurements and tests that should be performed however the focus of our efforts is to provide source code and transparency in order for the tests to be repeatable as well as having the ability to discuss how to improve testing.

\subsection{Measurements}
This section will describe what metrics will be collected and why.\\

\begin{table}
	\caption{Metric captured}
	\begin{tabular}{c l}
		\multicolumn{2}{c}{Metrics captured} \\
		\hline
		Client & Response time and throughput \\
		ESB & CPU \\ 
		Web service &  CPU \\
		\hline
	\end{tabular} \\
\end{table}
\subsubsection{Response time}
The amount of time elapsed since a request was sent to the time a response was received. 
The response time is measured because this is what a single user will be affected by the most, if the response time is very low the user will perceive the system as very fast and vice versa if the response time is too high.
\subsubsection{Throughput}
Amount of successful transactions performed per second (tps). A transaction is counted as successful if the response matches the expected values.
The value of throughput lays in how many users the system can serve in a single point of time. If the throughput is high the system will be able to handle many simultaneous users making the system efficient at handling a high load.



Response time and throughput are the most interesting numbers to investigate as they are very important for end users and systems. The more users a system can handle and the faster it does so the higher value the system will get in terms of scalability and performance per processing unit which in turn equals a lower operating cost where the system is able to handle a high amount of users whilst keeping the costs down.
CPU and RAM data will be measured in order to be able to make sure no hardware limitations occur during testing. The CPU on the web service is only collected to make sure that it doesn't act as a bottleneck while testing. Although this might not be the case in real world scenarios the aim is not to cap any hardware limitations because that would not give fair test results since the hardware would limit the performance of the system being tested and since the framework is supposed to give the involved system(s) free roam hardware limitations would be in straight contrast to what the framework is about.

\section{Test walktrough}
The tests described below are aimed at measuring the very basic roles of any ESB. 
The tests are very simple with the specific goal of producing a baseline for future tests. 
These basic tests have been chosen since anyone with the development knowledge of an ESB should be able to produce an ESB project capable of delivering a runnable project which exposes these basic funtionalities.

\subsection{Pure throughput}
No manipulation of the data will be done by the ESB in this test. The ESB will purely forward all request to the target web service as fast as possible. 
This test could simulate a service where the ESB exposes an inbound endpoint for other system to connect to, modularizing which service is running in the background thus giving a separation of concerns where the requesting client does not have to know about the responding web service, just that a web service is made available by the ESb.
A comparative test can be performed here as well and that is to not use the ESB which will show what performance impact the ESB adds. 

\centerline{\includegraphics[scale=0.43]{img/direct_proxy}}

\subsection{Routing}
In this test the ESB will, depending on the context of an incoming request from the Client, send the request to an appropriate web service which will append some data and return the request to the ESB which will send the response to the Client.
This represents the ability to have several systems behind an ESB all showing the same front to the outside.
This test is deemed basic because it is what an should do, separate the systems integration with each other, stepping in as a ``middle-man'' directing requests on behalf of the systems being integrated making the need for changing the systems minimal and just focus on the ESB. 
A test like this could simulate a load balancer where the ESB is a front for two or more systems each running an instance of the same service. Another thing this could simulate is different systems handling different (but similar) data, for example one system behind the ESB is handling user registrations and another one is handling user logins. The ESB can then look at the request payload and decide what user interaction is happening and thus mediate the request to the appropriate system.

\centerline{\includegraphics[scale=0.43]{img/Routing}}
\subsection{Message transformation}
The ESB will convert an incoming request to a different format and send it to a web service which will append some data and return the request to the ESB which will transform it back into the format the Client originally sent it.
Transformation is a huge deal for any ESB since two systems to be integrated probably will not speak the same language (XML, json etc) and even if they do they may not have the same format. Of course the systems need to be able to communicate with each others, without an ESB this could become cumbersome since all involved systems would have to be changed in order to understand what the others where saying, just imagine an old system written in COBOL or Assembler and making it communicate with a new system like a web service using REST \cite{whatisrest}. Integration like this cost both money and time and probably won't be future friendly with regards to maintenance.
This could make an ESB invaluable since the ESB would take care of receiving the incoming request in one format, decide where the request is to be sent, transform it to a format which the receiving system can understand, get a response back and transforming it to a format the original system which sent the request will understand.

\centerline{\includegraphics[scale=0.43]{img/transformation}}
\subsection{Artifacts and tools}
\begin{table}
	\caption{Software and tools}
	\begin{itemize}
		\item Client: Grinder \cite{whatisgrinder, kod}
		\item ESB: Mule \cite{whatismule, kod}
		\item Web service: Jax-WS \cite{whatisjaxws, kod}
		\item OS: Windows 7, 6.1.7600 build 7600
	\end{itemize}
\end{table}
In order to minimize the amount of factors that interfere in the tests we consider having at least three similar state of the art computers, connected to a high-speed network, essential.
It might not be of the greatest importance that the computers are state of the art but in order to not reach a hardware ceiling while testing, such machines are recommended. 
What's most important is that one computer is designated to run ESBs, one is designated to generate traffic(called Client) while the others are simple servers responding to the traffic generated (called Web service). 

This separating and designating of roles to machines minimizes different hardware affecting test results as the same machines perform the same roles in all tests and the only thing changed is the ESB. 

It also means that if other machines are used in other tests the data produced can be compared to ours and as such validate the data or identify faults in the tests. 
This validation can be done in two ways. 
First is to run the same software versions and compare the results. 
They should be similar deviating only in magnitude. The second is if using a newer or old software version the values when put in a graph will either have the same shape or show areas in which performance has changed, 
if it is the same shape but the magnitude is higher then that is most likely caused by faster machines being used and vice versa if its the same magnitude except in certain areas then that shows an improvement in the software.

\subsection{Variables and variable control}
No limitiations has been forseen except for hardware and notwork.
Hardware and network loads should be monitored so they are not close too 100\% as that would mean there is a major bottleneck present. 
All involved computers a run with the same operating system.
\subsection{Experiment schedule and execution sequence}
The three tests have two different focuses. First is to test scalability with an increasing amount of simulated clients (1, 20, 40, 80, 160) sending concurrent requests. 
The other is to test load-handling where a single client will send varying sizes of payload, 1KB, 50KB, 100KB, 500KB and 1MB.
\subsection{Validity threats}
This section discusses different validity threats.
\subsubsection{Different operating systems}
%Different operating system will effect test results 
%TODO säkerställ att unix inte påverkar resultaten nämnvärt
kan påvera men vi kommer att köra testerna på lite olika system så vi har ett hum om vilka förändringar det innebär i datan.
\subsubsection{Different hardware}
%TODO kör testerna en gång på /// så vi inte påverkas för mycket av hårdvara
see "different operating systems"
\subsubsection{Inefficient code}
We are not expert in the various programming languages and systems used to perform these tests and as such our code might be inefficient and even wrong. Inefficient code is not a problem as long as the same code is used in all tests. Erroneous code however is unmaintainable code and as such will require too be changed in the future and that will most likely affect the test results and test history. 
The possibilities of erroneous code has been limited by focusing the tests on very simple and basic functionality that doesn't require expert knowledge of the ESB in order to get results.
By actually providing the source code we have opened up the possibility for improvements and additions of more advanced tests which we feel is extremely important for a consistent testing framework used in academia and industry.

\subsection{Test results and analysis}

%TODO: fixa bättre start på texten.

We have used the framework to provide a test usage of it by benchmarkign a project created with mule.
First up is the computers used, the tests below where run on four different computers, all with the same specifications (see table \ref{table:hw-spec}).

\begin{table}
	\caption{Hardware configuration}
	\label{table:hw-spec}
	\begin{tabular}{c l}
		Component & Specification \\ 
		\hline
		CPU & Intel Core i7 920 @ 2.67GHz  \\
		RAM &  6,00 GB Triple-Channel DDR3 @ 533MHz (7-7-7-20) \\
		Network &  Intel(R) 82567LM-2 Gigabit Network Connection \\
		Motherboard &  Intel Corporation DX58SO (J1PR) \\
		Graphics &  256MB GeForce 7600 GS (MSI) \\
		Hard Drive &  488GB Western Digital WDC WD5001AALS-00L3B2 ATA Device (SATA) \\
		\hline
	\end{tabular} 
\end{table}

\begin{figure}
	\centerline{\includegraphics{img/proxy_fu_ip_tps}}
	\caption{TPS for direct proxy.}
	\label{fig:proxy-1-1}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/proxy_fu_ip_resp}}
	\caption{Mean response time for direct proxy.}
	\label{fig:proxy-1-2}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/proxy_fp_iu_tps}}
	\caption{TPS for direct proxy.}
	\label{fig:proxy-2-1}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/proxy_fp_iu_resp}}
	\caption{Mean response time for direct proxy.}
	\label{fig:proxy-2-2}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/mediation_fu_ip_tps}}
	\caption{TPS for content-based routing.}
	\label{fig:mediation-1-1}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/mediation_fu_ip_resp}}
	\caption{Mean response time for content-based routing.}
	\label{fig:mediation-1-2}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/mediation_fp_iu_tps}}
	\caption{TPS for content-based routing.}
	\label{fig:mediation-2-1}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/mediation_fp_iu_resp}}
	\caption{Mean response time for content-based routing.}
	\label{fig:mediation-2-2}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/transform_fu_ip_tps}}
	\caption{TPS for content transformation proxy.}
	\label{fig:transform-1-1}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/transform_fu_ip_resp}}
	\caption{Mean response time for content transformation proxy.}
	\label{fig:transform-1-2}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/transform_fp_iu_tps}}
	\caption{TPS for content transformation proxy.}
	\label{fig:transform-2-1}
\end{figure}

\begin{figure}
	\centerline{\includegraphics{img/transform_fp_iu_resp}}
	\caption{Mean response time for content transformation proxy.}
	\label{fig:transform-2-2}
\end{figure}