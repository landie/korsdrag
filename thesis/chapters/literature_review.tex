\section{Literature review results}
\label{sec:litrev}

The literature review has been focused on what the academic world knows and what the industrial world knows. Knowledge in this thesis is focused towards performance tests.
First the academic sources will be presented and their tests summarized, followed by the same procedure focusing on the industry and finally the entire literature review will be concluded in an overarching summary.

% - Present the papers that you have identified as your information source. Describe them, what type of papers they are, from what period; what do they have in common etc.
\subsection{Knowledge in academia}
\label{sec:academia_section}
This section will summaries our findings in academia. Beginning with a short presentation of papers found followed by a summary and analysis of the tests found within the papers.


"Enterprise Service Bus"\cite{falko07} by Falko Menge is a paper that explains the fundamentals of an ESB as well as introduces Mule with an example. Published in 2007 its example has become obsolete and outdated however the fundamentals still hold true as seen by later papers such as "Research of Enterprise Application Integration Based-on ESB" \cite{Jieming2010} by Jieming Wu and Xiaoli Tao as well as "Integration of Distributed Enterprise Applications: A Survey" \cite{HeIntegration} by Wu He and Li Da Xu. These are papers that focus on describing the history and evolution of software integration. They were published in 2010 and give an in depth view on how an ESB  operates.


"An Interoperability  Study  of ESB for C4I  Systems" \cite{Alghamdi2010} by Abdullah Alghamdi, Muhammad Nasir, Iftikhar Ahmad and Khalid A. Nafjan and  "Adopting and Evaluating Service Oriented Architecture in Industry" by Khalid Adam Nasr, Hans-Gerhard Gross and Arie van Deursen are papers showing the importance of ESBs in the modern world. Published in 2010 they represent a modern necessity for ESBs in industry.


"Service-Oriented Performance Modeling the MULE Enterprise Service Bus (ESB) Loan Broker Application " \cite{Brebner2009} by Paul Brebner is a paper from 2009 going trough how the author builds a integration solution and tests it, however the author tests the entire solution which isn't general enough for what we consider a performance test of an ESB. The author does however discuss some aspects of testing that are vital such as how and where to measure.

"Evaluating Open Source Enterprise Service Bus" \cite{Garcia2010} by F. J. Garcia-Jimenez and M. A. Martinez-Carreras, A. F. is the first paper found that performs a performance test however the test is limited in variation and magnitude. The paper was published in 2010 which makes the test results outdated since all ESBs in the test has received major updates since 2010.


"Enterprise Service Bus: A Performance Evaluation" \cite{Sanjay2011} by Sanjay P. Ahuja and Amit Patel  is the only paper found that performs a performance test directly aimed at the different ESBs with a varied test suite and varied measurements. Published in 2011 it is also the most recent paper found however all ESBs tested has received major updates since then and as such needs to be retested. 
Their test results seem to contain very low numbers when compared with the industrial tests containing numbers above 1000 TPS. 
This makes us question what system and ESB configuration they have used but there is no way for us to check any errors on their part as they have not published these details.


The above papers has as per the literature review design first been identified by its abstract and then read in detail to find those that describe the concept of an ESB and those that test ESBs in various ways. We have selected papers according to three topics. First is a basic ESB understanding and explanation in order to assert an understanding of how an ESB works and its history. We consider this important since in order to understand the importance of a software it is imperative one has a firm understanding of its fundamentals. After that fundamental has been established we concentrated on papers that shows a use for ESBs in real world industry and organizations. This in order to convey a sense of the use and importance of ESBs and research concerning it.
Finally we focused on papers that performs any kind of tests in order to establish an understanding of the current body of knowledge in the academic world. Most important were papers testing ESBs and not overall solutions, performance and not subjective feature checks.


\subsubsection{Academia summary}
This section is a summary of tests and scenarios found in our academic sources.

\begin{table}[H]
	\caption{Summary of academic papers and what test they perform}
	\begin{tabular}{c c c c c}

		Reference to paper & Year & Performance & Evaluation & ESBs \\ 
		\hline
		Nasr \cite{Nasr2010} & 2010 & - & - & - \\ 
		Alghamdi \cite{Alghamdi2010} & 2010 & - & X & Mule, Glassfish, Fuse\\
		Sanjay \cite{Sanjay2011} & 2011 & X & X & mule, servicemix, wso2 \\ 
		Garcia \cite{Garcia2010} & 2010 & X & X & Mule, Fuse, Petals \\
		He \cite{HeIntegration} & 2011 & - & - & -\\
		Jieming \cite{Jieming2010} & 2010 & - & - & - \\
		Brebner \cite{Brebner2009} & 2009 & - & - & Mule \\
		\hline
	\end{tabular}
	This table is a collection of the sources we have found and the essential information they contain.
	\\ 
	\\
	\\
	\caption{Summary of the scenarios in the academic performance tests}
	\begin{tabular}{c c c c}

		Test scenarios & Scenario 1 & Scenario 2 & Scenario 3 \\
		\hline
		Sanjay \cite{Sanjay2011} & Direct proxy & Routing & Mediation \\ 

		Garcia \cite{Garcia2010} & Direct proxy with security header & JMS bus & - \\ 
		\hline
	\end{tabular}
	This table is a collection of the scenarios performed in the sources we have found.
	\\
	\\
	\\
	\caption{Summary of metrics captured}
	\begin{tabular}{c c c c}
	Metrics &  Client & ESB & Web service \\
	\hline
	CPU & - & Sanjay \cite{Sanjay2011} & Sanjay \cite{Sanjay2011}\\
	Throughput & Sanjay \cite{Sanjay2011} & - & - \\
	Response time & Garcia \cite{Garcia2010} Sanjay \cite{Sanjay2011} & - & - \\
	Standard deviation & Garcia \cite{Garcia2010} & - & - \\
	\hline
	\end{tabular}
	\\
	\\
	Sanjay \cite{Sanjay2011} tests used a varied amount of users and payload while Garcia \cite{Garcia2010} only tested with an increasing amount of users.
\end{table}

The fact that we have only found two papers \cite{Sanjay2011,Garcia2010} performing tests is a very clear indication that the academic world does not perform performance test/analysis on ESBs. The ones we have found are all considered old in a rapidly changing world and all but one \cite{Sanjay2011} performs a test that we find adequately focusing on performance. 
It would also seem that Sanjay \cite{Sanjay2011} have looked at the tests performed in the industry \cite{Perera07,Perera07R2,Perera07R3,mulesoft08} as the tests and metrics captured closely align with the industrial tests however the numbers measured are wastly different. 
This shows the importance of publishing hardware specifications and tools configuration so following papers can reproduce and analyze data more accurately and improve on the testing framework.
Sanjay have added a CPU measurement on the ESB in order to measure relative performance between ESBs allowing the same throughput per CPU load percentage to be calculated.
The tests performed by Garcia \cite{Garcia2010} contribute by adding security but the tests themselves doesn't test the core functions enough for us to use them in our own framework. 
Adding security ontop of tests is a possible addition to the framework in the future but for now its at a higher technical level then we're aiming for in this thesis.


\subsection{Knowledge in industry}
\label{sec:industry_section}
This section will summarize our findings in the industry. Beginning with a short presentation of papers found followed by a summary and analysis of the tests found within the papers.


First of all we found an article by A. Mehta \cite{mehta11} which listed what the author thought were the best ESBs available in 2011. This is important as it provides us with a list of ESBs that we can pick and choose from when selecting candidates for our performance test and it provides us with focus points on where to start searching for performance tests performed by ESBs themselves. This is also the most recent article of its kin, as well as the largest that we found.


In 2007 WSO2 started with a series of three performance tests against other leading ESBs \cite{Perera07,Perera07R2,Perera07R3}. In the third they compare against Mule ESB which in turn responds with a performance test of their own from Mule \cite{mulesoft08}. The tests performed in these tests are sensible and aim to present an understanding of how the different ESBs perform while doing basic tasks. A problem however is that the results are from 2008 and later which mean that they are extremely out of date and maybe even more important is that they are very biased.


Mule has published a few articles that are not performance test but instead some kind of sales comparison with a number of other ESBs\cite{mulevsjboss,mulevsglassfish,mulevsservicemix}.
But we feel its important to include this anyway as we feel it shows a direction from doing performance tests to doing some sort of vague sales pitch without any numbers to back up their claims.

And finally we have read the Forrester report \cite{forrester11} from 2011 which is a industry initiated report that further visualizes the need for ESBs in modern software development, It is not performance oriented and includes non open-source ESBs.

\subsubsection{Industry summary}
This section is a summary of tests and scenarios found in our industrial sources.

\begin{table}[H]
	\caption{Summary of industrial papers and what tests they perform}
	\begin{tabular}{c c c c c}

		Reference to paper & Year & Performance & Evaluation & ESBs \\ 
		\hline	
		Falko \cite{falko07} & 2007 & - & - & - \\ 
		Fenner \cite{fenner03} & 2003 & - & - & - \\
		WSO2 \cite{Perera07} & 2007 & X & - & WSO2 \\
		WSO2 \cite{Perera07R2} & 2007 & X & - & WSO2, Mule, Servicemix\\
		WSO2 \cite{Perera07R3} & 2007 & X & - & WSO2, Proprietary, Mule, WSO2, Servicemix \\
		Mulesoft \cite{mulesoft08} & 2008 & X & - & Mule, WSO2\\
		Mulesoft \cite{mulevsjboss} & 2010 & - & X & Mule, Jboss ESB\\
		Mulesoft \cite{mulevsglassfish} & 2010 & - & X & Mule, Glassfish \\
		Mulesoft \cite{mulevsservicemix} & 2010 & - & X & Mule, Servicemix \\
		Forrester \cite{forrester11} & 2011 & - & X & Proprietary, Fuse, WSO2, Mule and more\\
		\hline
	\end{tabular}
	This table is a collection of the sources we have found and the essential information they contain.
	\\
	\\
	\\
	\caption{Summary of the scenarios in the industrial performance tests}
	\begin{tabular}{c c c c}
		\hline
		Test scenarios & Scenario 1 & Scenario 2 & Scenario 3 \\
		\hline
		Mulesoft \cite{mulesoft08} & Direct proxy & Routing & Mediation \\	
		WSO2 \cite{Perera07} & Direct proxy & Routing & Mediation \\
		WSO2 \cite{Perera07R2} & Direct proxy & Routing & Mediation \\
		WSO2 \cite{Perera07R3} & Direct proxy & Routing & Mediation \\
		\hline
	\end{tabular}
	This table is a collection of the scenarios performed in the sources we have found. 
	\\
	\\
	\\	
	\caption{Summary of metrics captured}
	\begin{tabular}{c c c c}
	Metrics &  Client & ESB & Web service \\
	\hline
	Throughput & Mulesoft \cite{mulesoft08} WSO2 \cite{Perera07R2,Perera07R3} & - & - \\
	Response time & WSO2 \cite{Perera07} & - & - \\
	\hline
	\end{tabular}
	\\
	\\
	All tests were performed with varied amounts of user and payload.
\end{table}

The industry seem to have a good understanding of how to test their products however they do not seem to update their results and as such they hold little value.
There also seems to be quite alot of rivalry in the different tests. 
It seems WSO2 started by doing a series of performance tests \cite{Perera07,Perera07R2,Perera07R3}  where Mule did not perform as well as Mule themselves think they should and such they did their own test \cite{mulesoft08} where the results pointed in their favour.
This shows a need for a independent third party to perform the testing as it will otherwise turn in to a slugfest where no results can be trusted. 

\subsection{Literature review conclusion}
In this section we will answer RQ 1 and 2 aswell as provide a foundation for answering RQ3.

It is apparent that the academic world is seriously lacking any kind of performance tests regarding the ESB field of software engineering. 
We found one paper by Sanjay \cite{Sanjay2011} that produced a test suite with a good enough scope and focus. 
It is however becoming outdated due to the fast pace of the industry and there are no collaborating papers supporting the results produced and as such it by itself hold little value. 
We have also during our own testing found Sanjays results very odd and since they have not presented the environment in which they performed the tests it's impossible to figure out why their numbers are strange. 
The industry has made a good effort in providing sensible tests that focuses on the basic performance but those results are old, outdated and most importantly biased as the different companies are direct competiters. 

We believe that \cite{Sanjay2011} and \cite{Perera07,Perera07R2,Perera07R3,mulesoft08} still holds some merit in regards to how tests should be performed but the actual results they have produced have not been confirmed by other independent sources and are now to old for reproduction. 
It is therefore our conclusion in regards to RQ1-2 that the current body of knowledge is very inaccurate and outdated however there is enough history for us to be able to start fresh.
We will focus on the scenarios found in \cite{Perera07,Perera07R2,Perera07R3,mulesoft08,Sanjay2011} as those seem to be focused on the core functionality and that is the best place to start.
These scenarios should also allow for atleast a comparison against older data and some conclusions regarding improvements in performance might be possible because of that.
We will in our test framework provide an up to date framework for performing these tests and most importantly we will provide the source code needed to replicate and analyze the tests.

